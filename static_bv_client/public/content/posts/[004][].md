# Algorithms for free
## And parallelism too


### Standard Algorithms

There are a multitude of algorithms available in the C++ Standard Template Library (STL).  Cppreference is a good resource https://en.cppreference.com/w/cpp/algorithm.  There's no need to have them all memorized but it is good to know what is available.  There is a good chance that something already exists that will do what you need.  It can save you a lot of time trying to implement it yourself and also make your code cleaner and more readable.

The STL algorithms operate on a range of elements that you specify by providing an iterator to the first element and another to one past the last element.  The standard containers have methods for begin() and end() respectively.  Consider the following example.

```cpp
#include <vector>
#include <algorithm>
#include <numeric>
#include <random>


constexpr unsigned AMOUNT_OF_WORK = 100;


int do_work(int n)
{
    std::random_device r;
    std::default_random_engine eng(r());
    std::uniform_int_distribution<int> uniform_dist(10, 1000);

    int sum = 0;

    for (unsigned i = 0; i < AMOUNT_OF_WORK; ++i)
    {
        sum += uniform_dist(eng) % 3;
    }

    return sum;
}


void process_vector(std::vector<int>& src, std::vector<int>& dst)
{
    auto const times_two = [](int& n) { n *= 2; };

    // double each element in src
    std::for_each(src.begin(), src.end(), times_two);

    // apply the do_work function to each value of src and store the results in dst
    std::transform(src.begin(), src.end(), dst.begin(), do_work);
}
```

The do_work function is intended to take some time generating a result.  It accumulates the modulus calculation of 100 randomly generated numbers.  We can adjust the amount of time it takes with the AMOUNT_OF_WORK constant.

The process function demonstrates the standard algorithms std::for_each and std::transform.  It does the following.
* Apply a lambda to each element of src, doubling them in place (https://en.cppreference.com/w/cpp/algorithm/for_each)
* Call the do_work function with each element of src and save the result in dst (https://en.cppreference.com/w/cpp/algorithm/transform)

Many people find it irritating to have to pass begin and end iterators to these functions instead of just the container like in many other languages.  Sometimes they resort to writing wrapper functions to make their code more concise.

```cpp
template <typename T>
void sort(T& container)
{
    std::sort(container.begin(), container.end());
}
```

This has the drawback of having to write an overload for each of the algorithm's overloads that you want to use.

Another option is the std::ranges namespace for algorithms.  That is a topic worthy of its own post but one thing it allows for is more concise function calls.

```cpp
std::ranges::sort(vec);
```




These algorithms operate on each element one at a time starting at the beginning and moving sequencially until the end.  For example, you can sort only the first 10 elements of a containiner.

```cpp
std::sort(vec.begin(), vec.begin() + 10);
```

### Parallelism

If your collections are quite large, then operating on each element one at a time can be a bottleneck in your application.  C++17 introduced the ability for many algorithms to use multi-threading in order to process several elements at the same time.  How this is executed will depend on the operating system and the computer's CPU.  What this means for developers is that this functionality is available without any extra programming.  We only need to pass a parameter indicating that we wish the algorithm to execute in parallel.

```cpp
#include <execution>


void process_vector_par(std::vector<int>& src, std::vector<int>& dst)
{
    auto const times_two = [](int& n) { n *= 2; };

    // double each element in src
    std::for_each(std::execution::par, src.begin(), src.end(), times_two);

    // apply the do_work function to each value of src and store the results in dst
    std::transform(std::execution::par, src.begin(), src.end(), dst.begin(), do_work);
}
```

This example is the same as the one above except that we passed the Execution Policy std::execution::par to std::for_each and std::transform.  This should faster but we need to test it.


### Speed Test

The following class can be used for timing code execution.  Copy and save it to a file called stopwatch.hpp

```cpp
#pragma once
#include <chrono>

class Stopwatch
{
private:
	std::chrono::system_clock::time_point start_;
	std::chrono::system_clock::time_point end_;
	bool is_on_ = false;

	std::chrono::system_clock::time_point now() { return std::chrono::system_clock::now(); }

public:
	Stopwatch()
	{
		start_ = now();
		end_ = start_;
	}

	void start()
	{
		start_ = now();
		is_on_ = true;
	}

	void stop()
	{
		end_ = now();
		is_on_ = false;
	}

	double get_time_milli()
	{
		std::chrono::duration<double, std::milli> delay = is_on_ ? now() - start_ : end_ - start_;

		return delay.count();
	}

	double get_time_sec()
	{
		std::chrono::duration<double> delay = is_on_ ? now() - start_ : end_ - start_;

		return delay.count();
	}

};
```

This program runs each example and outputs their execution times.

```cpp
#include <iostream>

#include "stopwatch.hpp"


constexpr unsigned ELEMENT_COUNT = 100000;


int main()
{
    Stopwatch sw;

    auto const print_time = [&](const char* msg) { std::cout << msg << ": " << sw.get_time_milli() << "ms\n"; };

    std::vector<int> src_vec(ELEMENT_COUNT);
    std::vector<int> dst_vec(ELEMENT_COUNT);

    // { 1, 2, 3, 4, ... , size }
    std::iota(src_vec.begin(), src_vec.end(), 1);

    std::cout << '\n';

    sw.start();
    process_vector(src_vec, dst_vec);
    print_time("sequential");

    // reset src_vec
    std::iota(src_vec.begin(), src_vec.end(), 1);

    sw.start();
    process_vector_par(src_vec, dst_vec);
    print_time("  parallel");
}
```

Output when running in debug mode.

![alt text](https://github.com/adam-lafontaine/CMS/raw/master/img/%5B004%5D/debug.png)

Output when running in release mode.

![alt text](https://github.com/adam-lafontaine/CMS/raw/master/img/%5B004%5D/release.png)

In both cases, the sequential version took almost 5 times longer to execute.  The times in this example are still very small but the time adds up when working with 